{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "from fastai.vision import *\n",
    "from fastai.data_block import _maybe_squeeze\n",
    "from fastai.callbacks import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from joblib import load, dump\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from ranger import *\n",
    "from mxresnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strt_split(x, y, n_folds=5, random_seed = 42, path=Path('')):  \n",
    "    try: \n",
    "        val_name = load('val_idx.joblib')\n",
    "    except:\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n",
    "        val_name = [(val_idx, trn_idx) for trn_idx, val_idx in skf.split(x, y)]\n",
    "        dump(val_name,'val_idx.joblib')\n",
    "    return val_name\n",
    "\n",
    "def modified_label_from_df(self, cols:IntsOrStrs=1, label_cls:Callable=None, **kwargs):\n",
    "    \"Label `self.items` from the values in `cols` in `self.inner_df`.\"\n",
    "    self.inner_df.labels.fillna('', inplace=True)\n",
    "    labels = self.inner_df.iloc[:,df_names_to_idx(cols, self.inner_df)]\n",
    "    assert labels.isna().sum().sum() == 0, f\"You have NaN values in column(s) {cols} of your dataframe, please fix it.\"\n",
    "    if is_listy(cols) and len(cols) > 1 and (label_cls is None or label_cls == MultiCategoryList):\n",
    "        new_kwargs,label_cls = dict(one_hot=True, classes= cols),MultiCategoryList\n",
    "        kwargs = {**new_kwargs, **kwargs}\n",
    "    return self._label_from_list(_maybe_squeeze(labels), label_cls=label_cls, **kwargs)\n",
    "\n",
    "\n",
    "def flattenAnneal(learn:Learner, lr:float, n_epochs:int, start_pct:float, SUFFIX = 'PHASE_1_COS'):\n",
    "    n = len(learn.data.train_dl)\n",
    "    anneal_start = int(n*n_epochs*start_pct)\n",
    "    anneal_end = int(n*n_epochs) - anneal_start\n",
    "    phases = [TrainingPhase(anneal_start).schedule_hp('lr', lr),\n",
    "             TrainingPhase(anneal_end).schedule_hp('lr', lr, anneal=annealing_cos)]\n",
    "    sched = GeneralScheduler(learn, phases)\n",
    "    learn.callbacks.append(sched)\n",
    "    learn.callbacks.append(SaveModelCallback(learn, every='improvement', monitor='valid_loss', name = f'{EXP_NAME}_{SUFFIX}'))\n",
    "    learn.fit(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('..')\n",
    "FOLD =0\n",
    "EXP_NAME =      f'NB_EXP_10_CV_{FOLD}'\n",
    "IMG_TRAIN_224 = PATH/'train_images_224'\n",
    "IMG_TEST_224  = PATH/'test_images_224'\n",
    "DF_TRAIN =      pd.read_csv(PATH/'train_labels_as_strings.csv')\n",
    "DF_SUBMI =      pd.read_csv(PATH/'stage_1_sample_submission.csv')\n",
    "BS =            384\n",
    "SZ =            224\n",
    "\n",
    "\n",
    "\n",
    "DF_SUBMI['fn'] = DF_SUBMI.ID.apply(lambda x: '_'.join(x.split('_')[:2]) + '.png')\n",
    "DF_TRAIN['labels'].fillna('', inplace=True)\n",
    "VAL_IDX = strt_split(DF_TRAIN['fn'], DF_TRAIN['labels'])[FOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ItemList.label_from_df = modified_label_from_df\n",
    "test_fns = DF_SUBMI.fn.unique()\n",
    "\n",
    "data = (ImageList.from_csv('..', 'train_labels_as_strings.csv', folder=IMG_TRAIN_224.name)\n",
    "        .split_by_idxs(valid_idx=VAL_IDX[0], train_idx=VAL_IDX[1])\n",
    "        .label_from_df(label_delim=' ')\n",
    "        .transform(tfms = get_transforms(),size=SZ)\n",
    "        .add_test('../' +IMG_TEST_224.name + '/' + test_fns)\n",
    "        .databunch(bs=BS))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_xrsa =  mxresnet50(c_out=data.c, sa=True)\n",
    "opt_func = partial(Ranger, betas=(0.95,0.99), eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data,\n",
    "                md_xrsa,\n",
    "                wd=1e-2,\n",
    "                bn_wd=False, \n",
    "                true_wd=True, \n",
    "                opt_func=opt_func,\n",
    "                metrics=[accuracy_thresh])\n",
    "\n",
    "learn.model = nn.DataParallel(learn.model)\n",
    "learn.to_fp16()\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.mixup(stack_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2/3\n",
    "learn.recorder.plot(skip_end=1)\n",
    "plt.axvline(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_thresh</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.096379</td>\n",
       "      <td>0.094411</td>\n",
       "      <td>0.967433</td>\n",
       "      <td>20:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.084853</td>\n",
       "      <td>0.080725</td>\n",
       "      <td>0.971553</td>\n",
       "      <td>20:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.079183</td>\n",
       "      <td>0.079181</td>\n",
       "      <td>0.972300</td>\n",
       "      <td>20:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.073785</td>\n",
       "      <td>0.074474</td>\n",
       "      <td>0.974261</td>\n",
       "      <td>20:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071993</td>\n",
       "      <td>0.070438</td>\n",
       "      <td>0.975138</td>\n",
       "      <td>20:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.070687</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>0.975460</td>\n",
       "      <td>20:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.067750</td>\n",
       "      <td>0.067530</td>\n",
       "      <td>0.976002</td>\n",
       "      <td>20:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.066519</td>\n",
       "      <td>0.066805</td>\n",
       "      <td>0.976321</td>\n",
       "      <td>20:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.067872</td>\n",
       "      <td>0.064937</td>\n",
       "      <td>0.976587</td>\n",
       "      <td>20:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.065047</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.976740</td>\n",
       "      <td>20:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063182</td>\n",
       "      <td>0.063474</td>\n",
       "      <td>0.977211</td>\n",
       "      <td>20:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.062243</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>0.977297</td>\n",
       "      <td>20:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.060670</td>\n",
       "      <td>0.062936</td>\n",
       "      <td>0.977317</td>\n",
       "      <td>20:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.062662</td>\n",
       "      <td>0.977453</td>\n",
       "      <td>20:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.059143</td>\n",
       "      <td>0.061206</td>\n",
       "      <td>0.977835</td>\n",
       "      <td>20:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.055499</td>\n",
       "      <td>0.059468</td>\n",
       "      <td>0.978635</td>\n",
       "      <td>20:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.051288</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.979331</td>\n",
       "      <td>20:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.056286</td>\n",
       "      <td>0.979781</td>\n",
       "      <td>20:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.043787</td>\n",
       "      <td>0.055966</td>\n",
       "      <td>0.980052</td>\n",
       "      <td>20:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.041329</td>\n",
       "      <td>0.055582</td>\n",
       "      <td>0.980156</td>\n",
       "      <td>20:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.09441084414720535.\n",
      "Better model found at epoch 1 with valid_loss value: 0.08072510361671448.\n",
      "Better model found at epoch 2 with valid_loss value: 0.07918119430541992.\n",
      "Better model found at epoch 3 with valid_loss value: 0.07447420060634613.\n",
      "Better model found at epoch 4 with valid_loss value: 0.07043765485286713.\n",
      "Better model found at epoch 5 with valid_loss value: 0.06934646517038345.\n",
      "Better model found at epoch 6 with valid_loss value: 0.06752996891736984.\n",
      "Better model found at epoch 7 with valid_loss value: 0.06680489331483841.\n",
      "Better model found at epoch 8 with valid_loss value: 0.06493663042783737.\n",
      "Better model found at epoch 10 with valid_loss value: 0.06347418576478958.\n",
      "Better model found at epoch 11 with valid_loss value: 0.06286603212356567.\n",
      "Better model found at epoch 13 with valid_loss value: 0.06266184896230698.\n",
      "Better model found at epoch 14 with valid_loss value: 0.06120621785521507.\n",
      "Better model found at epoch 15 with valid_loss value: 0.05946764349937439.\n",
      "Better model found at epoch 16 with valid_loss value: 0.05814026668667793.\n",
      "Better model found at epoch 17 with valid_loss value: 0.056285880506038666.\n",
      "Better model found at epoch 18 with valid_loss value: 0.055965643376111984.\n",
      "Better model found at epoch 19 with valid_loss value: 0.055582333356142044.\n",
      "set state called\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2/3\n",
    "flattenAnneal(learn, lr, 20, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(learn:Learner, sub_fn: str=f'{EXP_NAME}_COS', TTA: bool = False, dt_type = DatasetType.Test):\n",
    "    if TTA:\n",
    "        learn.to_fp32()\n",
    "        preds, targs = learn.TTA(ds_type=dt_type)\n",
    "        sub_fn = f'{sub_fn}_TTA'\n",
    "    else:\n",
    "        preds, targs = learn.get_preds(dt_type)\n",
    "    ids = []\n",
    "    labels = []\n",
    "\n",
    "    for fn, pred in zip(test_fns, preds):\n",
    "        for i, label in enumerate(data.train_ds.classes):\n",
    "            ids.append(f\"{fn.split('.')[0]}_{label}\")\n",
    "            predicted_probability = '{0:1.10f}'.format(pred[i].item())\n",
    "            labels.append(predicted_probability)\n",
    "    pd.DataFrame({'ID': ids, 'Label': labels}).to_csv(f'{sub_fn}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(learn, TTA=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo shutdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
